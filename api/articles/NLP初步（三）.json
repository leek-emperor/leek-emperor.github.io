{"title":"NLP初步（三）预训练词向量加载代码实战","uid":"1254a8f3f75ef701c93024f8482cdb21","slug":"NLP初步（三）","date":"2022-06-17T02:35:00.000Z","updated":"2022-10-05T13:48:21.938Z","comments":true,"path":"api/articles/NLP初步（三）.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664977691/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/steve-johnson-1pHVwou3mIM-unsplash_ofzkrb.jpg","content":"<p>大家好，我是丹星，一个摸鱼转行的炼丹师。今天的内容干货满满，全是实战内容哟。</p>\n<h1 id=\"预训练词向量\"><a href=\"#预训练词向量\" class=\"headerlink\" title=\"预训练词向量\"></a>预训练词向量</h1><p>之前我们介绍了word2vec词向量的训练方法，其实还有更多的词向量训练方法，常见的比如glove和fasttext，感兴趣的朋友可以去另外了解，这里就不对原理进行太多的讲解。如果想要获取现成的词向量文件，可以去对应的官网上下载，当然在kaggle上有人整理好了现成的词向量放在了Dataset中，方便在kaggle跑代码时快速调用，以下列出几个本人经常用的Dataset：</p>\n<ul>\n<li>Glove ：<a href=\"https://www.kaggle.com/datasets/yesornope/glove6b\">https://www.kaggle.com/datasets/yesornope/glove6b</a></li>\n<li>Fasttext：<a href=\"https://fasttext.cc/docs/en/english-vectors.html\">https://fasttext.cc/docs/en/english-vectors.html</a></li>\n<li>英文词向量汇总：<a href=\"https://www.kaggle.com/datasets/iezepov/gensim-embeddings-dataset?select=glove.twitter.27B.200d.gensim\">https://www.kaggle.com/datasets/iezepov/gensim-embeddings-dataset?select=glove.twitter.27B.200d.gensim</a></li>\n<li>中文：<a href=\"https://www.kaggle.com/datasets?search=chinese+word+embedding\">https://www.kaggle.com/datasets?search=chinese+word+embedding</a></li>\n</ul>\n<h1 id=\"代码实战\"><a href=\"#代码实战\" class=\"headerlink\" title=\"代码实战\"></a>代码实战</h1><p>既然有了预训练的词向量，我们要如何匹配自己的数据集，然后加载到模型的Embedding层中去呢？本文仍然以新冠推文情感分析的数据集为例，使用glove预训练词向量进行文本情感分类。</p>\n<p>代码仍然在kaggle公开：</p>\n<p><a href=\"https://www.kaggle.com/code/leekemperor/pretrain-word-embedding-in-text-classification?scriptVersionId=98573268\">https://www.kaggle.com/code/leekemperor/pretrain-word-embedding-in-text-classification?scriptVersionId=98573268</a></p>\n<p>首先，导入相关的库</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> re\n<span class=\"token keyword\">import</span> copy\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">import</span> Embedding\n<span class=\"token keyword\">from</span> pathlib <span class=\"token keyword\">import</span> Path\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data <span class=\"token keyword\">import</span> Dataset<span class=\"token punctuation\">,</span> DataLoader<span class=\"token punctuation\">,</span> random_split\n\n<span class=\"token keyword\">from</span> torch <span class=\"token keyword\">import</span> nn<span class=\"token punctuation\">,</span>optim\n<span class=\"token keyword\">from</span> tqdm<span class=\"token punctuation\">.</span>notebook <span class=\"token keyword\">import</span> tqdm\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">import</span> Adam<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>加载数据和词向量文件</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">root_path <span class=\"token operator\">=</span> Path<span class=\"token punctuation\">(</span><span class=\"token string\">\"../input/covid-19-nlp-text-classification\"</span><span class=\"token punctuation\">)</span>  \ntrain_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>root_path <span class=\"token operator\">/</span> <span class=\"token string\">\"Corona_NLP_train.csv\"</span><span class=\"token punctuation\">,</span>encoding<span class=\"token operator\">=</span><span class=\"token string\">'latin'</span><span class=\"token punctuation\">)</span>  \ntest_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>root_path <span class=\"token operator\">/</span> <span class=\"token string\">\"Corona_NLP_test.csv\"</span><span class=\"token punctuation\">,</span>encoding<span class=\"token operator\">=</span><span class=\"token string\">'latin'</span><span class=\"token punctuation\">)</span>\n\nembedding_dim <span class=\"token operator\">=</span> <span class=\"token number\">300</span>  <span class=\"token comment\"># 设定需要的embedding长度</span>\n\n<span class=\"token comment\"># word_dict是一个单词于id的映射字典，</span>\n<span class=\"token comment\"># &lt;pading>的意思是补0，&lt;unk>代表不认识的单词，其实就是glove词向量中没有的单词都会被认为是&lt;unk></span>\nword_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'&lt;pading>'</span><span class=\"token punctuation\">:</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"&lt;unk>\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\"># 加载对应长度的glove预训练词向量，维度越大的词向量加载越慢，300维的词向量文件有1G</span>\nglove_path <span class=\"token operator\">=</span> Path<span class=\"token punctuation\">(</span><span class=\"token string\">\"/kaggle/input/glove6b\"</span><span class=\"token punctuation\">)</span>  \nglove_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>glove_path <span class=\"token operator\">/</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"glove.6B.</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>embedding_dim<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">d.txt\"</span></span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> quoting<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 生成对应的字典形式，key为单词，value为词向量</span>\nglove_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>key<span class=\"token punctuation\">:</span> val<span class=\"token punctuation\">.</span>values <span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> val <span class=\"token keyword\">in</span> glove_df<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>对文本进行分词处理，并构建文本词表，输入模型的句子必须是一样长度，所以要设定一个长度，超出长度的部分截断，不足的部分补0（padding）。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">word_tokenize</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\" \n    这是一个切分单词的函数，这个函数除了简单了分词之外，\n    还会将word_dict补充完整，生成完整的词表映射\n    \"\"\"</span>\n    word_index <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    pat <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token string\">r\"[\\w]+|[.,!?;|]\"</span><span class=\"token punctuation\">)</span> \n    tokens <span class=\"token operator\">=</span> pat<span class=\"token punctuation\">.</span>findall<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> tokens<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> token <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> word_dict<span class=\"token punctuation\">:</span>\n            word_dict<span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> token <span class=\"token keyword\">in</span> glove_dict <span class=\"token keyword\">else</span> word_dict<span class=\"token punctuation\">[</span><span class=\"token string\">\"&lt;unk>\"</span><span class=\"token punctuation\">]</span>\n        word_index<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> word_index\n\n<span class=\"token comment\"># 训练集和测试集分词</span>\ntrain_text <span class=\"token operator\">=</span> train_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"OriginalTweet\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> s<span class=\"token punctuation\">:</span> word_tokenize<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest_text <span class=\"token operator\">=</span> test_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"OriginalTweet\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> s<span class=\"token punctuation\">:</span> word_tokenize<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 词表大小85091</span>\n\ntrain_text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>describe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 设定句子最大长度为240</span>\n<span class=\"token triple-quoted-string string\">'''\ncount    41157.000000\nmean        36.377093\nstd         13.705114\nmin          1.000000\n25%         26.000000\n50%         37.000000\n75%         47.000000\nmax        232.000000\nName: OriginalTweet, dtype: float64\n'''</span>\n\nMAX_LENGTH <span class=\"token operator\">=</span> <span class=\"token number\">240</span>  <span class=\"token comment\"># 最大句子长度</span>\ntrain_text <span class=\"token operator\">=</span> train_text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>MAX_LENGTH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>MAX_LENGTH<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ntest_text <span class=\"token operator\">=</span> test_text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>MAX_LENGTH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>MAX_LENGTH<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ns2i <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'Positive'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Extremely Positive'</span><span class=\"token punctuation\">:</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Neutral'</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Extremely Negative'</span><span class=\"token punctuation\">:</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Negative'</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">&#125;</span>\ntrain_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>train_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span>s2i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\ntest_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>test_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span>s2i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 预训练的词向量矩阵，这个后面会直接输入embedding层</span>\nglove_embeddings <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> embedding_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> word_dict<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> v<span class=\"token operator\">==</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        glove_embeddings<span class=\"token punctuation\">[</span>v<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>embedding_dim<span class=\"token punctuation\">)</span>\n    glove_embeddings<span class=\"token punctuation\">[</span>v<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> glove_dict<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> k <span class=\"token keyword\">in</span> glove_dict <span class=\"token keyword\">else</span> glove_dict<span class=\"token punctuation\">[</span><span class=\"token string\">\"&lt;unk>\"</span><span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>数据集构建</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">CommentDataset</span><span class=\"token punctuation\">(</span>Dataset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>texts<span class=\"token punctuation\">,</span>labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>texts<span class=\"token operator\">=</span>texts\n        self<span class=\"token punctuation\">.</span>labels<span class=\"token operator\">=</span>labels\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__len__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>texts<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__getitem__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>item<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        item 为数据索引，迭代取第item条数据\n        \"\"\"</span>\n        text<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>texts<span class=\"token punctuation\">[</span>item<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">)</span>\n        label<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">[</span>item<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'text_id'</span><span class=\"token punctuation\">:</span>text<span class=\"token punctuation\">,</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">:</span>label<span class=\"token punctuation\">&#125;</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_data_loader</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>batch_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    ds<span class=\"token operator\">=</span>CommentDataset<span class=\"token punctuation\">(</span>\n        texts <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">,</span>\n        labels<span class=\"token operator\">=</span>y<span class=\"token punctuation\">.</span>values\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> DataLoader<span class=\"token punctuation\">(</span>\n        ds<span class=\"token punctuation\">,</span>\n        batch_size<span class=\"token operator\">=</span>batch_size\n    <span class=\"token punctuation\">)</span>\n\nBATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">128</span>\ntrain_data_loader <span class=\"token operator\">=</span> create_data_loader<span class=\"token punctuation\">(</span>train_text<span class=\"token punctuation\">,</span>train_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> BATCH_SIZE<span class=\"token punctuation\">)</span>\nval_data_loader <span class=\"token operator\">=</span> create_data_loader<span class=\"token punctuation\">(</span>test_text<span class=\"token punctuation\">,</span>test_df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> BATCH_SIZE<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>模型构建，这里搭了两个模型，第一个是词向量后接全连接层，第二个是接的GRU，之后看下这两种做法的表现怎样，虽然毋庸置疑是GRU更好。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>weight<span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span><span class=\"token number\">300</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Model<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>embedding <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span>weight<span class=\"token punctuation\">,</span>freeze<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 仍然训练词向量</span>\n        self<span class=\"token punctuation\">.</span>Linear <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>embedding_dim<span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        X <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>embedding<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span> <span class=\"token comment\"># [b,240] ==> [b,240,300]</span>\n        X <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># [b,240] ==> [b,300]</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span> <span class=\"token comment\"># [b,300] ==> [b,5]</span>\n        <span class=\"token keyword\">return</span> out\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">GRUModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>weight<span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span><span class=\"token number\">300</span><span class=\"token punctuation\">,</span>hidden_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>GRUModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>embedding <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span>weight<span class=\"token punctuation\">,</span>freeze<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 仍然训练词向量</span>\n        self<span class=\"token punctuation\">.</span>rnn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>GRU<span class=\"token punctuation\">(</span><span class=\"token number\">300</span><span class=\"token punctuation\">,</span>hidden_size<span class=\"token punctuation\">,</span>batch_first<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>num_layers<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>bidirectional<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>dropout<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>linear <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>hidden_size<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>hidden_size<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>out <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>hidden_size<span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        X <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>embedding<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span> <span class=\"token comment\"># [b,240] ==> [b,240,300]</span>\n        X<span class=\"token punctuation\">,</span>_ <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rnn<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>     <span class=\"token comment\">#  [b,240,300] ==>  [b, 240, hidden_size*2]</span>\n        X <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>linear<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># [b, 240, hidden_size*2] ==> [b, 240, hidden_size]</span>\n        X <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># [b, 240, hidden_size] ==> [b,hidden_size]</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span> <span class=\"token comment\"># [b,hidden_size] ==> [b,5]</span>\n        <span class=\"token keyword\">return</span> out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>模型训练</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> collections <span class=\"token keyword\">import</span> defaultdict\nhistory <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">)</span>\n\ndevice <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 设置CUDA</span>\nN_EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">10</span>     <span class=\"token comment\"># 设置模型训练次数</span>\nlearning_rate <span class=\"token operator\">=</span> <span class=\"token number\">3e-4</span>  <span class=\"token comment\"># 初始学习率</span>\n\nmodel<span class=\"token operator\">=</span> GRUModel<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>from_numpy<span class=\"token punctuation\">(</span>glove_embeddings<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 优化器</span>\noptimizer <span class=\"token operator\">=</span> Adam<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>learning_rate<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 损失</span>\ncriterion <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> tqdm<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>N_EPOCHS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#启用模型的训练模式</span>\n    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># 定义损失</span>\n    epoch_loss <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    epoch_acc <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    val_number <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> batch <span class=\"token keyword\">in</span> train_data_loader<span class=\"token punctuation\">:</span>\n        text_id <span class=\"token operator\">=</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'text_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n        label <span class=\"token operator\">=</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n        predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>text_id<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span>\n        epoch_loss <span class=\"token operator\">+=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        preds <span class=\"token operator\">=</span> predictions<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n        epoch_acc <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>preds<span class=\"token operator\">==</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        val_number <span class=\"token operator\">+=</span> label<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    history<span class=\"token punctuation\">[</span><span class=\"token string\">'train_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>epoch_loss <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_data_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    history<span class=\"token punctuation\">[</span><span class=\"token string\">'train_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>epoch_acc <span class=\"token operator\">/</span> val_number<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">轮，训练Loss：'</span></span><span class=\"token punctuation\">,</span>epoch_loss <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_data_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'，训练准确率：'</span><span class=\"token punctuation\">,</span>epoch_acc <span class=\"token operator\">/</span> val_number<span class=\"token punctuation\">)</span>\n\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># 初始化损失</span>\n    epoch_loss <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    epoch_acc <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    val_number <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token comment\">#不计算梯度</span>\n    <span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>no_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> batch <span class=\"token keyword\">in</span> val_data_loader<span class=\"token punctuation\">:</span>\n            text_id <span class=\"token operator\">=</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'text_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n            label <span class=\"token operator\">=</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n            predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>text_id<span class=\"token punctuation\">)</span>\n            loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">)</span>\n            epoch_loss <span class=\"token operator\">+=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            preds <span class=\"token operator\">=</span> predictions<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n            epoch_acc <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>preds<span class=\"token operator\">==</span>label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            val_number <span class=\"token operator\">+=</span> label<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    history<span class=\"token punctuation\">[</span><span class=\"token string\">'test_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>epoch_loss <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>val_data_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    history<span class=\"token punctuation\">[</span><span class=\"token string\">'test_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>epoch_acc <span class=\"token operator\">/</span> val_number<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">轮，测试Loss：'</span></span><span class=\"token punctuation\">,</span>epoch_loss <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>val_data_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'，测试准确率：'</span><span class=\"token punctuation\">,</span>epoch_acc <span class=\"token operator\">/</span> val_number<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-'</span><span class=\"token operator\">*</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p><img src=\"https://res.cloudinary.com/dg7crzfct/image/upload/v1664977502/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/640_5_mzndao.png\"></p>\n<p><img src=\"https://res.cloudinary.com/dg7crzfct/image/upload/v1664977503/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/640_6_zrl693.png\"></p>\n<p>可以看到GRU还是具有明显优势的，收敛轮数少，并且分数高。当然RNN的显著缺点之一就是时间开销比较大。</p>\n","text":"大家好，我是丹星，一个摸鱼转行的炼丹师。今天的内容干货满满，全是实战内容哟。 预训练词向量之前我们介绍了word2vec词向量的训练方法，其实还有更多的词向量训练方法，常见的比如glove和fasttext，感兴趣的朋友可以去另外了解，这里就不对原理进行太多的讲解。如果想要获取现...","link":"","photos":[],"count_time":{"symbolsCount":"7.7k","symbolsTime":"7 mins."},"categories":[{"name":"NLP","slug":"NLP","count":3,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":3,"path":"api/tags/NLP.json"},{"name":"数据挖掘","slug":"数据挖掘","count":3,"path":"api/tags/数据挖掘.json"},{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F\"><span class=\"toc-text\">预训练词向量</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">代码实战</span></a></li></ol>","author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}},"mapped":true,"prev_post":{"title":"数据竞赛实战（一）点击反欺诈预测，2022年3月第二名","uid":"ecfdc9266c75f1a5dbb47c4430fd00a9","slug":"数据竞赛实战（一）点击反欺诈预测，2022年3月第二名","date":"2022-06-18T02:40:00.000Z","updated":"2022-10-05T14:17:46.190Z","comments":true,"path":"api/articles/数据竞赛实战（一）点击反欺诈预测，2022年3月第二名.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664978472/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/alex-sh-H6Kl0yCnCwc-unsplash_nubtec.jpg","text":"大家好，这里是丹星，今天的项目是我之前比赛的代码啦，这个分数还是比较靠前的，总排名应该能有前20吧，代码我4月份其实已经开源在AI Studio了（https://aistudio.baidu.com/aistudio/projectdetail/3735300）。 比赛介绍广告...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[{"name":"数据挖掘","slug":"数据挖掘","count":1,"path":"api/categories/数据挖掘.json"}],"tags":[{"name":"数据竞赛","slug":"数据竞赛","count":1,"path":"api/tags/数据竞赛.json"},{"name":"xgboost","slug":"xgboost","count":1,"path":"api/tags/xgboost.json"},{"name":"lightGBM","slug":"lightGBM","count":1,"path":"api/tags/lightGBM.json"}],"author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}}},"next_post":{"title":"NLP初步（二）从TF-IDF到Word2Vec","uid":"fee5334a6e9b786f2386b28178cc2265","slug":"NLP初步（二）","date":"2022-06-16T04:00:00.000Z","updated":"2022-10-05T13:37:51.067Z","comments":true,"path":"api/articles/NLP初步（二）.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664976916/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/tonmoy-iftekhar--Ryi8beHwgg-unsplash_blf8bk.jpg","text":"大家好，这里是丹星，一个摸鱼转行的炼丹师。今天我们来聊一聊词袋模型的简单进化版——TFIDF，以及之后主流的文本表示方式词向量的开山之作——Wrod2Vec。 TF-IDF昨天我们谈到词袋模型其实就是将每个句子的词频转化为了一个高维稀疏的向量，TF—IDF正是基于词袋的结果进行了...","link":"","photos":[],"count_time":{"symbolsCount":"2.7k","symbolsTime":"2 mins."},"categories":[{"name":"NLP","slug":"NLP","count":3,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":3,"path":"api/tags/NLP.json"},{"name":"数据挖掘","slug":"数据挖掘","count":3,"path":"api/tags/数据挖掘.json"},{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"}],"author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}}}}