{"title":"NLP初步（一）从词袋模型说开去","uid":"3a2a27adc97b520f5d4502f70de41100","slug":"NLP初步（一）词袋","date":"2022-06-15T05:01:00.000Z","updated":"2022-10-05T13:02:44.561Z","comments":true,"path":"api/articles/NLP初步（一）词袋.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664974885/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/zeynep-sumer-e96xL67JrfM-unsplash_uplnho.jpg","content":"<p>大家好，这里是丹星，一个摸鱼转行的炼丹师。今天是僵尸公众号复活的第一天，从今天开始，我将不定期更新机器学习和深度学习相关方面知识。</p>\n<p>我们来简单介绍一下自然语言处理( Natural Language Processing, NLP)。NLP是人类语言、计算机科学和人工智能的一个子领域，是目前深度学习的一个分支方向。说得比较通俗一点，就是使得模型能够认识人类的语言，这里包括文本和语音，但是我在今后比较长的时间里不会涉及到语音的相关内容，如果感兴趣可以自行搜索李宏毅老师的公开课进行学习。</p>\n<p>进入正题，众所周知机器不能直接识别文本内容，包括众多编程语言中的字符串类型其实仍然是转换成了二进制来存储。因此，我们需要文字转化为机器能看懂的数字，然后再去做其他事，本文介绍早期的文本转化方法——**词袋模型（Bow)**。</p>\n<h1 id=\"Bow模型\"><a href=\"#Bow模型\" class=\"headerlink\" title=\"Bow模型\"></a>Bow模型</h1><p>举个栗子，词袋模型的表达非常简洁，如下面str为文本，一共有两句话，word2index中写出了该段文本中所有的词，一共四个。那么我们默认从0到3号分别对应I到dog，则词袋模型表现为了bow的形式。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">str &#x3D; [&#39;I love you&#39;,&#39;you love dog&#39;]   # 文本\n\nword2index &#x3D; &#123;&#39;I&#39;:0,&#39;you&#39;:1,&#39;love&#39;:2,&#39;dog&#39;:3&#125; # 词的映射\n\n# 词袋模型\nbow &#x3D; [\n    [1,1,1,0],\n    [0,1,1,1]\n]<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>这就是最简单的词袋模型的表达，但需要注意的是，这里所有词只出现了一次。如果某句话dog出现了2次，那么对应位置（3号位）就会是2。说白了，词袋模型统计了所有句子中出现的词语，然后给某个词一个位置，每句话的对应位置代表了该词在句子中出现的个数，《精通特征工程》所画的示意图如下</p>\n<p><img src=\"https://res.cloudinary.com/dg7crzfct/image/upload/v1664974677/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221005205723_s0zn4y.jpg\" alt=\"图片\"></p>\n<h2 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h2><ul>\n<li>比较简单，便于理解</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><ul>\n<li>词袋的维数（dim）和文本所含的词数是正相关的，当文本过大，词数较多时，引发了维数灾难。</li>\n<li>忽略了文本中单词的顺序和结构信息，比如“我爱你”和“你爱我”在词袋模型的表述中是一样的。</li>\n</ul>\n<p><strong>代码实践（Show Code)</strong></p>\n<p>选用数据集为：冠状病毒推文 NLP - 文本分类，地址：<a href=\"https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification?select=Corona_NLP_train.csv%E3%80%82\">https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification?select=Corona_NLP_train.csv。</a></p>\n<p>各位可以自行下载。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np \n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd \ndf<span class=\"token operator\">=</span>pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'Corona_NLP_train.csv'</span><span class=\"token punctuation\">,</span>encoding<span class=\"token operator\">=</span><span class=\"token string\">'latin'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 五分类的情感分析</span>\ns2i <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'Positive'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Extremely Positive'</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Neutral'</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Extremely Negative'</span><span class=\"token punctuation\">:</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token string\">'Negative'</span><span class=\"token punctuation\">:</span><span class=\"token number\">4</span><span class=\"token punctuation\">&#125;</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span>s2i<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 情感映射成数字</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># sklearn的词袋模型函数，可以直接调用</span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> CountVectorizer  \n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LogisticRegression  <span class=\"token comment\"># 逻辑回归</span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split <span class=\"token comment\"># 切分数据</span>\n<span class=\"token keyword\">from</span> sklearn <span class=\"token keyword\">import</span> metrics       <span class=\"token comment\"># 评估指标</span>\n\nx<span class=\"token operator\">=</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'OriginalTweet'</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 这个是推文的文本</span>\ny<span class=\"token operator\">=</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'Sentiment'</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># 切分训练集和测试集</span>\nx_train<span class=\"token punctuation\">,</span>x_test<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span>y_test<span class=\"token operator\">=</span>train_test_split<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>random_state<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\nvect<span class=\"token operator\">=</span>CountVectorizer<span class=\"token punctuation\">(</span>min_df<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># min_df=5：出现次数低于5次的词语忽略</span>\nnames<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>vect<span class=\"token punctuation\">.</span>get_feature_names<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># names是词袋模型所有的词语</span>\nx_train_trans<span class=\"token operator\">=</span>vect<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span>     <span class=\"token comment\"># 将x_train转化为词袋模型表示</span>\n\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>vect<span class=\"token punctuation\">.</span>get_feature_names<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 9363，有9363个词，所以对应了9363个特征维度</span>\nx_train_trans<span class=\"token punctuation\">.</span>shape            <span class=\"token comment\"># (30867, 9363)</span>\n\n<span class=\"token comment\"># 逻辑回归训练</span>\nmodel <span class=\"token operator\">=</span> LogisticRegression<span class=\"token punctuation\">(</span>C<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train_trans<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\npredict<span class=\"token operator\">=</span>model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>vect<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 在测试集上预测</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Auccuracy &#123;:.2%&#125;'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>metrics<span class=\"token punctuation\">.</span>accuracy_score<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span>predict<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># Auccuracy 61.53%</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'F1_score &#123;:.2%&#125;'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>metrics<span class=\"token punctuation\">.</span>f1_score<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span>predict<span class=\"token punctuation\">,</span>average<span class=\"token operator\">=</span><span class=\"token string\">'macro'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># F1_score 62.08%</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>metrics<span class=\"token punctuation\">.</span>classification_report<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span>predict<span class=\"token punctuation\">,</span>target_names<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>s2i<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>分类报告结果图：</p>\n<p><img src=\"https://res.cloudinary.com/dg7crzfct/image/upload/v1664974737/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/640_swhyrm.png\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>欢迎关注这个摸鱼更新的公众号<br><img src=\"https://res.cloudinary.com/dg7crzfct/image/upload/v1664947192/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/qrcode_for_gh_6b9e2ea53ffc_258_lkxhbj.jpg\"></p></blockquote>\n","feature":true,"text":"大家好，这里是丹星，一个摸鱼转行的炼丹师。今天是僵尸公众号复活的第一天，从今天开始，我将不定期更新机器学习和深度学习相关方面知识。 我们来简单介绍一下自然语言处理( Natural Language Processing, NLP)。NLP是人类语言、计算机科学和人工智能的一个子...","link":"","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[{"name":"NLP","slug":"NLP","count":1,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":1,"path":"api/tags/NLP.json"},{"name":"数据挖掘","slug":"数据挖掘","count":1,"path":"api/tags/数据挖掘.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Bow%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">Bow模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BC%98%E7%82%B9\"><span class=\"toc-text\">优点</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BC%BA%E7%82%B9\"><span class=\"toc-text\">缺点</span></a></li></ol></li></ol>","author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}},"mapped":true,"prev_post":{"title":"JSONP解决跨域问题","uid":"e0afe5470d30cea57d222ddde269ba0c","slug":"JSONP解决跨域","date":"2022-08-20T12:17:00.000Z","updated":"2022-10-05T06:50:24.466Z","comments":true,"path":"api/articles/JSONP解决跨域.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664952605/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/JSONP%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F/deepmind-OVzy5oIDPp8-unsplash_xqqxrb.jpg","text":"JSONP是JSON with Padding的略称，JSONP为民间提出的一种跨域解决方案，通过客户端的script标签发出的请求方式。 什么时候才有跨域问题?浏览器的ajax，去请求不同的源的数据，就会出现跨域问题。 问: img&#x2F;srcipt标签的src有跨域问题...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"前端","slug":"前端","count":1,"path":"api/categories/前端.json"}],"tags":[{"name":"网络请求","slug":"网络请求","count":1,"path":"api/tags/网络请求.json"},{"name":"JSONP","slug":"JSONP","count":1,"path":"api/tags/JSONP.json"},{"name":"Javascript","slug":"Javascript","count":1,"path":"api/tags/Javascript.json"}],"author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}}},"next_post":{}}