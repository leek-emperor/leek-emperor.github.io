{"title":"数据竞赛实战（一）点击反欺诈预测，2022年3月第二名","uid":"ecfdc9266c75f1a5dbb47c4430fd00a9","slug":"数据竞赛实战（一）点击反欺诈预测，2022年3月第二名","date":"2022-06-18T02:40:00.000Z","updated":"2022-10-05T14:17:46.190Z","comments":true,"path":"api/articles/数据竞赛实战（一）点击反欺诈预测，2022年3月第二名.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664978472/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/alex-sh-H6Kl0yCnCwc-unsplash_nubtec.jpg","content":"<p>大家好，这里是丹星，今天的项目是我之前比赛的代码啦，这个分数还是比较靠前的，总排名应该能有前20吧，代码我4月份其实已经开源在AI Studio了（<a href=\"https://aistudio.baidu.com/aistudio/projectdetail/3735300%EF%BC%89%E3%80%82\">https://aistudio.baidu.com/aistudio/projectdetail/3735300）。</a></p>\n<h1 id=\"比赛介绍\"><a href=\"#比赛介绍\" class=\"headerlink\" title=\"比赛介绍\"></a>比赛介绍</h1><p>广告欺诈是数字营销需要面临的重要挑战之一，点击会欺诈浪费广告主大量金钱，同时对点击数据会产生误导作用。<strong>本次比赛提供了约50万次点击数据。</strong>特别注意：我们对数据进行了模拟生成，对某些特征含义进行了隐藏，并进行了脱敏处理。<br>请<strong>预测用户的点击行为是否为正常点击，还是作弊行为。</strong>点击欺诈预测适用于各种信息流广告投放，banner广告投放，以及百度网盟平台，帮助商家鉴别点击欺诈，锁定精准真实用户。<br>本项目使用LightGBM和XGBoost模型进行最后分类，分数分别为<strong>89.29</strong>和<strong>89.31</strong>，结果取平均后分数为最后分数<strong>89.3213</strong>。之前的特征工程也借鉴了AI Studio其他的一些开源方法，在此表示感谢。<strong>以下为变量说明。</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">字段</th>\n<th align=\"left\">类型</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">sid</td>\n<td align=\"left\">string</td>\n<td align=\"left\">样本id&#x2F;请求会话sid</td>\n</tr>\n<tr>\n<td align=\"left\">package</td>\n<td align=\"left\">string</td>\n<td align=\"left\">媒体信息，包名（已加密）</td>\n</tr>\n<tr>\n<td align=\"left\">version</td>\n<td align=\"left\">string</td>\n<td align=\"left\">媒体信息，app版本</td>\n</tr>\n<tr>\n<td align=\"left\">android_id</td>\n<td align=\"left\">string</td>\n<td align=\"left\">媒体信息，对外广告位ID（已加密）</td>\n</tr>\n<tr>\n<td align=\"left\">media_id</td>\n<td align=\"left\">string</td>\n<td align=\"left\">媒体信息，对外媒体ID（已加密）</td>\n</tr>\n<tr>\n<td align=\"left\">apptype</td>\n<td align=\"left\">int</td>\n<td align=\"left\">媒体信息，app所属分类</td>\n</tr>\n<tr>\n<td align=\"left\">timestamp</td>\n<td align=\"left\">bigint</td>\n<td align=\"left\">请求到达服务时间，单位ms</td>\n</tr>\n<tr>\n<td align=\"left\">location</td>\n<td align=\"left\">int</td>\n<td align=\"left\">用户地理位置编码（精确到城市）</td>\n</tr>\n<tr>\n<td align=\"left\">fea_hash</td>\n<td align=\"left\">int</td>\n<td align=\"left\">用户特征编码（具体物理含义略去）</td>\n</tr>\n<tr>\n<td align=\"left\">fea1_hash</td>\n<td align=\"left\">int</td>\n<td align=\"left\">用户特征编码（具体物理含义略去）</td>\n</tr>\n<tr>\n<td align=\"left\">cus_type</td>\n<td align=\"left\">int</td>\n<td align=\"left\">用户特征编码（具体物理含义略去）</td>\n</tr>\n<tr>\n<td align=\"left\">ntt</td>\n<td align=\"left\">int</td>\n<td align=\"left\">网络类型 0-未知, 1-有线网, 2-WIFI, 3-蜂窝网络未知, 4-2G, 5-3G, 6–4G</td>\n</tr>\n<tr>\n<td align=\"left\">carrier</td>\n<td align=\"left\">string</td>\n<td align=\"left\">设备使用的运营商 0-未知, 46000-移动, 46001-联通, 46003-电信</td>\n</tr>\n<tr>\n<td align=\"left\">os</td>\n<td align=\"left\">string</td>\n<td align=\"left\">操作系统，默认为android</td>\n</tr>\n<tr>\n<td align=\"left\">osv</td>\n<td align=\"left\">string</td>\n<td align=\"left\">操作系统版本</td>\n</tr>\n<tr>\n<td align=\"left\">lan</td>\n<td align=\"left\">string</td>\n<td align=\"left\">设备采用的语言，默认为中文</td>\n</tr>\n<tr>\n<td align=\"left\">dev_height</td>\n<td align=\"left\">int</td>\n<td align=\"left\">设备高</td>\n</tr>\n<tr>\n<td align=\"left\">dev_width</td>\n<td align=\"left\">int</td>\n<td align=\"left\">设备宽</td>\n</tr>\n<tr>\n<td align=\"left\">dev_ppi</td>\n<td align=\"left\">int</td>\n<td align=\"left\">屏幕分辨率</td>\n</tr>\n</tbody></table>\n<h1 id=\"比赛代码\"><a href=\"#比赛代码\" class=\"headerlink\" title=\"比赛代码\"></a>比赛代码</h1><h2 id=\"数据加载\"><a href=\"#数据加载\" class=\"headerlink\" title=\"数据加载\"></a>数据加载</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> warnings\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> StratifiedKFold<span class=\"token punctuation\">,</span>KFold\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score<span class=\"token punctuation\">,</span>roc_auc_score\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> StratifiedKFold\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n\n<span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBClassifier\n<span class=\"token keyword\">import</span> lightgbm <span class=\"token keyword\">as</span> lgb\n<span class=\"token keyword\">import</span> pickle\n\nwarnings<span class=\"token punctuation\">.</span>filterwarnings<span class=\"token punctuation\">(</span><span class=\"token string\">'ignore'</span><span class=\"token punctuation\">)</span>\n\npd<span class=\"token punctuation\">.</span>set_option<span class=\"token punctuation\">(</span><span class=\"token string\">'display.max_columns'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">#最多显示5列</span>\npd<span class=\"token punctuation\">.</span>set_option<span class=\"token punctuation\">(</span><span class=\"token string\">'display.max_rows'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">150</span><span class=\"token punctuation\">)</span><span class=\"token comment\">#最多显示10行</span>\n<span class=\"token comment\"># 数据加载</span>\ntrain <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'train.csv'</span><span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'test1.csv'</span><span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> test<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\ntrain <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n\nall_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train<span class=\"token punctuation\">,</span>test<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h2 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 长度特征</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 设备高宽比、设备面积</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_rate'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_height'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_width'</span><span class=\"token punctuation\">]</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_area'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_height'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_width'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 面积与分辨率比</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_area_ppi'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_ppi'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_area'</span><span class=\"token punctuation\">]</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_area_ppi'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>np<span class=\"token punctuation\">.</span>isinf<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'dev_area_ppi'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n<span class=\"token comment\"># 利用数量特征构造。</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">unique</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    result <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x<span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>result<span class=\"token punctuation\">[</span>each<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> each <span class=\"token keyword\">in</span> x<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> x\n\n\n<span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'dev_height'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'dev_width'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'media_id'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'package'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'apptype'</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'android_id'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    all_df<span class=\"token punctuation\">[</span>f<span class=\"token operator\">+</span><span class=\"token string\">'_value_count'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>unique<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span>f<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># lan的处理</span>\n<span class=\"token comment\"># set(test['lan'].unique()) - set(train['lan'].unique()) &#123;'in_id', 'zh-us'&#125;</span>\n<span class=\"token comment\"># 测试集里面多出来了这两个&#123;'in_id', 'zh-us'&#125;，结果查询，这个语言号不存在，所以我们等会筛选出预测集中这两个的样本，直接判断为欺诈(样本只有两个)</span>\nle <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'lan'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'lan'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'str'</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'lan'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'lan'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ntrain <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>notnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ntest <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n\n<span class=\"token comment\"># 处理osv</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">trans_osv</span><span class=\"token punctuation\">(</span>osv<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    osv <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>osv<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'Android_'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'十核20G_HD'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'Android'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'W'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#     if osv == 'nan' or osv == 'GIONEE_YNGA':</span>\n<span class=\"token comment\">#         result = 810</span>\n    <span class=\"token keyword\">if</span> <span class=\"token string\">'_'</span> <span class=\"token keyword\">in</span> osv<span class=\"token punctuation\">:</span>\n        osv <span class=\"token operator\">=</span> osv<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'_'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> osv\n\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>trans_osv<span class=\"token punctuation\">)</span>\nidx <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token string\">'other'</span> <span class=\"token keyword\">if</span> x <span class=\"token keyword\">in</span> idx <span class=\"token keyword\">else</span> x<span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">)</span>\n\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>trans_osv<span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token string\">'other'</span> <span class=\"token keyword\">if</span> x <span class=\"token keyword\">in</span> idx <span class=\"token keyword\">else</span> x<span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># set(test['lan'].unique()) - set(train['lan'].unique())   &#123;'120', '446', '71300', 'GIONEE'&#125;</span>\n<span class=\"token comment\"># 这四个东西训练集没有出现，直接判定为欺诈(4个样本)</span>\n\nle <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nle<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">|</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">[</span><span class=\"token string\">'osv'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 直接判定为欺诈的sid</span>\nTrick_id <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1260961</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1393628</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1356887</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1911347</span><span class=\"token punctuation\">,</span><span class=\"token number\">1298847</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1629795</span><span class=\"token punctuation\">]</span>\n\ntrain<span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># os不要，都是安卓</span>\ntrain<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'os'</span><span class=\"token punctuation\">,</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'os'</span><span class=\"token punctuation\">,</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 时间类特征</span>\n\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>fromtimestamp<span class=\"token punctuation\">(</span>x<span class=\"token operator\">/</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>fromtimestamp<span class=\"token punctuation\">(</span>x<span class=\"token operator\">/</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># train和test都是从2019-06-03凌晨到2019-06-10凌晨</span>\n\n<span class=\"token comment\"># 分解时间</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'day'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>day\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'weekday'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>weekday\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'hour'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>hour\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'minute'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>minute\n\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'day'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>day\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'weekday'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>weekday\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'hour'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>hour\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'minute'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>minute\n\nstart_time <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>start_time\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>days<span class=\"token operator\">*</span><span class=\"token number\">24</span> <span class=\"token operator\">+</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>seconds<span class=\"token operator\">/</span><span class=\"token number\">3600</span> <span class=\"token comment\"># 按小时来计算</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>start_time\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>days<span class=\"token operator\">*</span><span class=\"token number\">24</span> <span class=\"token operator\">+</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>seconds<span class=\"token operator\">/</span><span class=\"token number\">3600</span> <span class=\"token comment\"># 按小时来计算</span>\n\n\n<span class=\"token comment\"># 对时间差做分桶</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">//</span><span class=\"token number\">13</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp_diff'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">//</span><span class=\"token number\">13</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#特征清洗version</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">rep</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>isdigit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">elif</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\"v\"</span> <span class=\"token keyword\">or</span> <span class=\"token string\">\"V\"</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isdigit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'version'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'version'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>rep<span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'version'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'version'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>rep<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#类别特征</span>\ncate_features <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'apptype'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'carrier'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ntt'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'location'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'cus_type'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'media_id'</span><span class=\"token punctuation\">,</span>\n<span class=\"token string\">'dev_width'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'dev_height'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'android_id'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 构造fea_hash_len特征</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash_len'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 如果fea_hash很长或者很小，都归为0，否则为自己的本身</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token number\">0</span> <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">10</span> <span class=\"token keyword\">or</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span><span class=\"token number\">8</span> <span class=\"token keyword\">else</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token number\">0</span> <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span><span class=\"token number\">8</span> <span class=\"token keyword\">else</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token number\">0</span> <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">10</span> <span class=\"token keyword\">or</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span><span class=\"token number\">8</span> <span class=\"token keyword\">else</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token number\">0</span> <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;=</span><span class=\"token number\">8</span> <span class=\"token keyword\">else</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nall_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train<span class=\"token punctuation\">,</span>test<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'str'</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'str'</span><span class=\"token punctuation\">)</span>\nall_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'fea1_hash'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> fea <span class=\"token keyword\">in</span> cate_features<span class=\"token punctuation\">:</span>\n    all_df<span class=\"token punctuation\">[</span>fea<span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span>fea<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">)</span>\n    all_df<span class=\"token punctuation\">[</span>fea<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> le<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>all_df<span class=\"token punctuation\">[</span>fea<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nall_df <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'dev_ppi'</span><span class=\"token punctuation\">,</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ntrain <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">!=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\ntest <span class=\"token operator\">=</span> all_df<span class=\"token punctuation\">[</span>all_df<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h2 id=\"模型训练\"><a href=\"#模型训练\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">feature <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfeature<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span><span class=\"token string\">'sid'</span><span class=\"token punctuation\">)</span>\nfeature<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">)</span>\ntrain<span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">'''\n&lt;class 'pandas.core.frame.DataFrame'>\nInt64Index: 500000 entries, 0 to 499999\nData columns (total 33 columns):\n #   Column                  Non-Null Count   Dtype  \n---  ------                  --------------   -----  \n 0   android_id              500000 non-null  int64  \n 1   apptype                 500000 non-null  int64  \n 2   carrier                 500000 non-null  int64  \n 3   dev_height              500000 non-null  int64  \n 4   dev_width               500000 non-null  int64  \n 5   lan                     500000 non-null  int64  \n 6   media_id                500000 non-null  int64  \n 7   ntt                     500000 non-null  int64  \n 8   osv                     500000 non-null  int64  \n 9   package                 500000 non-null  int64  \n 10  version                 500000 non-null  int64  \n 11  fea_hash                500000 non-null  int64  \n 12  location                500000 non-null  int64  \n 13  fea1_hash               500000 non-null  int64  \n 14  cus_type                500000 non-null  int64  \n 15  fea1_hash_len           500000 non-null  int64  \n 16  fea_hash_len            500000 non-null  int64  \n 17  dev_rate                500000 non-null  float64\n 18  dev_area                500000 non-null  float64\n 19  dev_area_ppi            500000 non-null  float64\n 20  dev_height_value_count  500000 non-null  int64  \n 21  dev_width_value_count   500000 non-null  int64  \n 22  media_id_value_count    500000 non-null  int64  \n 23  package_value_count     500000 non-null  int64  \n 24  apptype_value_count     500000 non-null  int64  \n 25  android_id_value_count  500000 non-null  int64  \n 26  fea1_hash_value_count   500000 non-null  int64  \n 27  fea_hash_value_count    500000 non-null  int64  \n 28  day                     500000 non-null  int64  \n 29  weekday                 500000 non-null  int64  \n 30  hour                    500000 non-null  int64  \n 31  minute                  500000 non-null  int64  \n 32  timestamp_diff          500000 non-null  int64  \ndtypes: float64(3), int64(30)\nmemory usage: 129.7 MB\n'''</span>\nX <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span>\ny <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span>\nX_test <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># LGB XGB 5折交叉验证</span>\n<span class=\"token keyword\">from</span> lightgbm <span class=\"token keyword\">import</span> LGBMClassifier\n<span class=\"token keyword\">def</span> <span class=\"token function\">lgb_xgb_train</span><span class=\"token punctuation\">(</span>KF<span class=\"token punctuation\">,</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>X_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    seed <span class=\"token operator\">=</span> <span class=\"token number\">2022</span>\n    lgb <span class=\"token operator\">=</span> LGBMClassifier<span class=\"token punctuation\">(</span>num_leaves<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span>\n                           max_depth<span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span>\n                           learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.005</span><span class=\"token punctuation\">,</span>\n                           n_estimators<span class=\"token operator\">=</span><span class=\"token number\">5000</span><span class=\"token punctuation\">,</span>\n                           subsample<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span>\n                           feature_fraction<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span>\n                           reg_alpha<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>\n                           reg_lambda<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>\n                           random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">,</span>\n                           metric<span class=\"token operator\">=</span><span class=\"token string\">'auc'</span><span class=\"token punctuation\">,</span>\n                           boosting_type<span class=\"token operator\">=</span><span class=\"token string\">'gbdt'</span><span class=\"token punctuation\">,</span>\n                           subsample_freq<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                           bagging_fraction<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span>verbose<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    xgb<span class=\"token operator\">=</span>XGBClassifier<span class=\"token punctuation\">(</span>\n            max_depth<span class=\"token operator\">=</span><span class=\"token number\">13</span><span class=\"token punctuation\">,</span> learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.005</span><span class=\"token punctuation\">,</span> n_estimators<span class=\"token operator\">=</span><span class=\"token number\">2400</span><span class=\"token punctuation\">,</span> \n            objective<span class=\"token operator\">=</span><span class=\"token string\">'binary:logistic'</span><span class=\"token punctuation\">,</span>\n            subsample<span class=\"token operator\">=</span><span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span> colsample_bytree<span class=\"token operator\">=</span><span class=\"token number\">0.4</span><span class=\"token punctuation\">,</span>n_jobs<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">,</span> \n            min_child_samples<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> eval_metric<span class=\"token operator\">=</span><span class=\"token string\">'auc'</span><span class=\"token punctuation\">,</span> reg_lambda<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>verbosity<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n    xgb_prob <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    lgb_prob <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    skf <span class=\"token operator\">=</span> StratifiedKFold<span class=\"token punctuation\">(</span>n_splits<span class=\"token operator\">=</span>KF<span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">2022</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>train_index<span class=\"token punctuation\">,</span> test_index<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>skf<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        X_train<span class=\"token punctuation\">,</span> X_val <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n        y_train<span class=\"token punctuation\">,</span> y_val <span class=\"token operator\">=</span> y<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">次训练'</span></span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 训练</span>\n        xgb <span class=\"token operator\">=</span> xgb<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span>\n                      eval_metric<span class=\"token operator\">=</span><span class=\"token string\">'auc'</span><span class=\"token punctuation\">,</span>eval_set<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">,</span>y_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                      verbose<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n        lgb <span class=\"token operator\">=</span> lgb<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span>y_train<span class=\"token punctuation\">,</span>\n                      eval_set<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">,</span> y_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>eval_metric<span class=\"token operator\">=</span><span class=\"token string\">'auc'</span><span class=\"token punctuation\">,</span>\n                              verbose <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 正式预测</span>\n        xgb_prob <span class=\"token operator\">+=</span> xgb<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>KF\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Xgboost:第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">次训练的AUC</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>roc_auc_score<span class=\"token punctuation\">(</span>y_val<span class=\"token punctuation\">,</span>xgb<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">,第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">次训练的Accuracy</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>accuracy_score<span class=\"token punctuation\">(</span>y_val<span class=\"token punctuation\">,</span>xgb<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n        lgb_prob <span class=\"token operator\">+=</span> lgb<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>KF\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'LightGBM:第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">次训练的AUC</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>roc_auc_score<span class=\"token punctuation\">(</span>y_val<span class=\"token punctuation\">,</span>lgb<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">,第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">次训练的Accuracy</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>accuracy_score<span class=\"token punctuation\">(</span>y_val<span class=\"token punctuation\">,</span>lgb<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> xgb_prob<span class=\"token punctuation\">,</span>lgb_prob\n\n\nxgb_prob<span class=\"token punctuation\">,</span>lgb_prob <span class=\"token operator\">=</span> lgb_xgb_train<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>X_test<span class=\"token punctuation\">)</span>\nsubmit <span class=\"token operator\">=</span> test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\nsubmit<span class=\"token punctuation\">[</span><span class=\"token string\">'xgb_prob'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> xgb_prob\nsubmit<span class=\"token punctuation\">[</span><span class=\"token string\">'lgb_prob'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> lgb_prob\nsubmit<span class=\"token punctuation\">[</span><span class=\"token string\">'融合'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> xgb_prob <span class=\"token operator\">+</span> lgb_prob\nsubmit<span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> submit<span class=\"token punctuation\">[</span><span class=\"token string\">'融合'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token number\">1</span> <span class=\"token keyword\">if</span> x<span class=\"token operator\">>=</span><span class=\"token number\">1</span> <span class=\"token keyword\">else</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\nTrick_id <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1260961</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1393628</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1356887</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1911347</span><span class=\"token punctuation\">,</span><span class=\"token number\">1298847</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1629795</span><span class=\"token punctuation\">]</span>\nsubmit<span class=\"token punctuation\">[</span>submit<span class=\"token punctuation\">[</span><span class=\"token string\">'sid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span>x <span class=\"token keyword\">in</span> Trick_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'xgb_prob'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\nsubmit<span class=\"token punctuation\">[</span>submit<span class=\"token punctuation\">[</span><span class=\"token string\">'sid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span>x <span class=\"token keyword\">in</span> Trick_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'lgb_prob'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>","text":"大家好，这里是丹星，今天的项目是我之前比赛的代码啦，这个分数还是比较靠前的，总排名应该能有前20吧，代码我4月份其实已经开源在AI Studio了（https://aistudio.baidu.com/aistudio/projectdetail/3735300）。 比赛介绍广告...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[{"name":"数据挖掘","slug":"数据挖掘","count":1,"path":"api/categories/数据挖掘.json"}],"tags":[{"name":"数据竞赛","slug":"数据竞赛","count":1,"path":"api/tags/数据竞赛.json"},{"name":"xgboost","slug":"xgboost","count":1,"path":"api/tags/xgboost.json"},{"name":"lightGBM","slug":"lightGBM","count":1,"path":"api/tags/lightGBM.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%AF%94%E8%B5%9B%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">比赛介绍</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%AF%94%E8%B5%9B%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">比赛代码</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD\"><span class=\"toc-text\">数据加载</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B\"><span class=\"toc-text\">特征工程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">模型训练</span></a></li></ol></li></ol>","author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}},"mapped":true,"prev_post":{"title":"JSONP解决跨域问题","uid":"e0afe5470d30cea57d222ddde269ba0c","slug":"JSONP解决跨域","date":"2022-08-20T12:17:00.000Z","updated":"2022-10-05T06:50:24.466Z","comments":true,"path":"api/articles/JSONP解决跨域.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664952605/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/JSONP%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F/deepmind-OVzy5oIDPp8-unsplash_xqqxrb.jpg","text":"JSONP是JSON with Padding的略称，JSONP为民间提出的一种跨域解决方案，通过客户端的script标签发出的请求方式。 什么时候才有跨域问题?浏览器的ajax，去请求不同的源的数据，就会出现跨域问题。 问: img&#x2F;srcipt标签的src有跨域问题...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"前端","slug":"前端","count":1,"path":"api/categories/前端.json"}],"tags":[{"name":"网络请求","slug":"网络请求","count":1,"path":"api/tags/网络请求.json"},{"name":"JSONP","slug":"JSONP","count":1,"path":"api/tags/JSONP.json"},{"name":"Javascript","slug":"Javascript","count":1,"path":"api/tags/Javascript.json"}],"author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}}},"next_post":{"title":"NLP初步（三）预训练词向量加载代码实战","uid":"1254a8f3f75ef701c93024f8482cdb21","slug":"NLP初步（三）","date":"2022-06-17T02:35:00.000Z","updated":"2022-10-05T13:48:21.938Z","comments":true,"path":"api/articles/NLP初步（三）.json","keywords":null,"cover":"https://res.cloudinary.com/dg7crzfct/image/upload/v1664977691/%E6%96%87%E7%AB%A0%E7%B4%A0%E6%9D%90%E5%BA%93/NLP%E7%9B%B8%E5%85%B3/steve-johnson-1pHVwou3mIM-unsplash_ofzkrb.jpg","text":"大家好，我是丹星，一个摸鱼转行的炼丹师。今天的内容干货满满，全是实战内容哟。 预训练词向量之前我们介绍了word2vec词向量的训练方法，其实还有更多的词向量训练方法，常见的比如glove和fasttext，感兴趣的朋友可以去另外了解，这里就不对原理进行太多的讲解。如果想要获取现...","link":"","photos":[],"count_time":{"symbolsCount":"7.7k","symbolsTime":"7 mins."},"categories":[{"name":"NLP","slug":"NLP","count":3,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":3,"path":"api/tags/NLP.json"},{"name":"数据挖掘","slug":"数据挖掘","count":3,"path":"api/tags/数据挖掘.json"},{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"}],"author":{"name":"风离","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"略懂数据挖掘、NLP和推荐算法的前炼丹师，目前沉迷JS、React的前端硕狗。 <br /> @ <b>公众号：丹星X</b>","socials":{"github":"https://github.com/leek-emperor","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/ma-xing-yu-71","csdn":"https://blog.csdn.net/weixin_44008395?type=blog","juejin":"https://juejin.cn/user/1042800253352664","customs":{}}}}}